{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f7d89f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "25f17a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = Path('./result/readability-indexes')\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "generated_simplified = pd.read_csv(base_folder / 'generated-simplified.csv')\n",
    "reference_simplified  = pd.read_csv(base_folder / 'reference-simplified.csv')\n",
    "reference_complete = pd.read_csv(base_folder / 'reference-complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "95075f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2025_ufc_inova_1\n",
       "1    2025_ufc_inova_8\n",
       "2    2025_ufc_inova_7\n",
       "3    2025_ufc_inova_3\n",
       "4    2025_ufc_inova_2\n",
       "5    2025_ufc_inova_6\n",
       "6    2025_ufc_inova_5\n",
       "7    2025_ufc_inova_4\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_complete['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "34e153c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_readability_cols = ['flesch_ease','gulpease'] \n",
    "grade_level_readability_cols = ['flesch_kincaid','ari','gunning_fog','coleman_liau']\n",
    "metrics_cols = scale_readability_cols + grade_level_readability_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf878c47",
   "metadata": {},
   "source": [
    "### Comparando arquivos originais com os gerados por cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c005c982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(generated_with_generated\n",
       " phi4:latest                       1.165699\n",
       " qwen2.5:14b                       0.839890\n",
       " deepseek-r1:14b                  -0.130338\n",
       " qwen2.5-coder:32b                -1.589942\n",
       " gemma3:4b                        -2.167815\n",
       " llama3.2:latest                  -3.365564\n",
       " granite3-dense:8b                -3.598144\n",
       " cow/gemma2_tools:2b              -4.451446\n",
       " granite3-dense:2b                -5.360311\n",
       " granite-code:8b                  -6.026275\n",
       " gemini-2.5-flash-preview-04-17         NaN\n",
       " gemini-2.5-pro-preview-05-06           NaN\n",
       " phi3:latest                            NaN\n",
       " Name: zscore_mean, dtype: float64,\n",
       " generated_with_generated\n",
       " phi4:latest                       2.510296\n",
       " qwen2.5:14b                       2.424960\n",
       " deepseek-r1:14b                   2.148312\n",
       " qwen2.5-coder:32b                 1.703727\n",
       " gemma3:4b                         1.512010\n",
       " llama3.2:latest                   1.179181\n",
       " granite3-dense:8b                 1.106616\n",
       " cow/gemma2_tools:2b               0.860743\n",
       " granite3-dense:2b                 0.606926\n",
       " granite-code:8b                   0.398176\n",
       " gemini-2.5-flash-preview-04-17         NaN\n",
       " gemini-2.5-pro-preview-05-06           NaN\n",
       " phi3:latest                            NaN\n",
       " Name: minmax_mean, dtype: float64)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = reference_complete.merge(generated_simplified,on='name',how='inner',suffixes=(\"\",'_generated'))\n",
    "\n",
    "for col in scale_readability_cols:\n",
    "    merged[col+\"_improvement\"] = ((merged[col+\"_generated\"]- merged[col]) / merged[col+\"_generated\"]) * 100\n",
    "for col in grade_level_readability_cols:\n",
    "    merged[col+\"_improvement\"] = ((merged[col] -merged[col+\"_generated\"]) / merged[col]) * 100 \n",
    "\n",
    "improvement_methods = [col+\"_improvement\" for col in metrics_cols]\n",
    "agg_methods = {col:\"mean\" for col in improvement_methods}\n",
    "\n",
    "average_improvement_per_model = merged.groupby('generated_with_generated').agg(agg_methods)\n",
    "\n",
    "zscores = average_improvement_per_model[improvement_methods].apply(zscore)\n",
    "\n",
    "exclude_invalid_models = ~((zscores.index.str.startswith('gemini')) | (zscores.index.str.startswith('phi3')))\n",
    "zscores['zscore_mean'] = zscores[exclude_invalid_models].sum(axis=1)\n",
    "best_zscore = zscores.loc[zscores['zscore_mean'].idxmax()]\n",
    "\n",
    "minmaxes = pd.DataFrame(scaler.fit_transform(average_improvement_per_model[improvement_methods]), columns = improvement_methods, index = average_improvement_per_model.index)\n",
    "exclude_invalid_models = ~(minmaxes.index.str.startswith('gemini') |(minmaxes.index.str.startswith(\"phi3\")))\n",
    "minmaxes['minmax_mean'] = minmaxes[exclude_invalid_models].sum(axis=1)\n",
    "best_minmax = minmaxes.loc[minmaxes['minmax_mean'].idxmax()]\n",
    "\n",
    "\n",
    "zscores.sort_values(by='zscore_mean',ascending=False)['zscore_mean'],minmaxes.sort_values(by='minmax_mean',ascending=False)['minmax_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0fc94d",
   "metadata": {},
   "source": [
    "### Comparando arquivos originais resumidos com os gerados por cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dc098f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(generated_with_generated\n",
       " qwen2.5:14b                        1.628393\n",
       " phi4:latest                        0.838930\n",
       " deepseek-r1:14b                    0.041306\n",
       " granite3-dense:2b                 -0.019110\n",
       " gemma3:4b                         -0.094447\n",
       " qwen2.5-coder:32b                 -0.118496\n",
       " granite3-dense:8b                 -1.250926\n",
       " llama3.2:latest                   -1.515129\n",
       " granite-code:8b                   -4.498649\n",
       " cow/gemma2_tools:2b               -5.581902\n",
       " phi3:latest                      -10.396431\n",
       " gemini-2.5-flash-preview-04-17          NaN\n",
       " gemini-2.5-pro-preview-05-06            NaN\n",
       " Name: zscore_mean, dtype: float64,\n",
       " generated_with_generated\n",
       " qwen2.5:14b                       3.415003\n",
       " phi4:latest                       3.151866\n",
       " deepseek-r1:14b                   2.953923\n",
       " qwen2.5-coder:32b                 2.895531\n",
       " granite3-dense:2b                 2.881012\n",
       " gemma3:4b                         2.875202\n",
       " granite3-dense:8b                 2.534994\n",
       " llama3.2:latest                   2.482745\n",
       " granite-code:8b                   1.585880\n",
       " cow/gemma2_tools:2b               1.326023\n",
       " phi3:latest                       0.000000\n",
       " gemini-2.5-flash-preview-04-17         NaN\n",
       " gemini-2.5-pro-preview-05-06           NaN\n",
       " Name: minmax_mean, dtype: float64)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = reference_simplified.merge(generated_simplified,on='name',how='inner',suffixes=(\"\",'_generated'))\n",
    "\n",
    "for col in scale_readability_cols:\n",
    "    merged[col+\"_improvement\"] = ((merged[col+\"_generated\"]- merged[col]) / merged[col+\"_generated\"]) * 100\n",
    "for col in grade_level_readability_cols:\n",
    "    merged[col+\"_improvement\"] = ((merged[col] -merged[col+\"_generated\"]) / merged[col]) * 100 \n",
    "\n",
    "improvement_methods = [col+\"_improvement\" for col in metrics_cols]\n",
    "agg_methods = {col:\"mean\" for col in improvement_methods}\n",
    "\n",
    "average_improvement_per_model = merged.groupby('generated_with_generated').agg(agg_methods)\n",
    "\n",
    "zscores = average_improvement_per_model[improvement_methods].apply(zscore)\n",
    "\n",
    "zscores['zscore_mean'] = zscores[~zscores.index.str.startswith('gemini')].sum(axis=1)\n",
    "best_zscore = zscores.loc[zscores['zscore_mean'].idxmax()]\n",
    "\n",
    "minmaxes = pd.DataFrame(scaler.fit_transform(average_improvement_per_model[improvement_methods]), columns = improvement_methods, index = average_improvement_per_model.index)\n",
    "minmaxes['minmax_mean'] = minmaxes[~minmaxes.index.str.startswith('gemini')].sum(axis=1)\n",
    "best_minmax = minmaxes.loc[minmaxes['minmax_mean'].idxmax()]\n",
    "\n",
    "zscores.sort_values(by='zscore_mean',ascending=False)['zscore_mean'],minmaxes.sort_values(by='minmax_mean',ascending=False)['minmax_mean']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
